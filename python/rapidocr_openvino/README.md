## rapidocr_openvino

**ğŸš©æ³¨æ„ï¼šåŸºäºç›®å‰`openvino==2022.2.0`ç‰ˆï¼Œåœ¨æ¨ç†æ‰¹é‡å›¾åƒæ—¶ï¼Œå­˜åœ¨ç”³è¯·å†…å­˜ä¸é‡Šæ”¾çš„é—®é¢˜ï¼Œè¯¦æƒ…å¯å‚è§[issue11939](https://github.com/openvinotoolkit/openvino/issues/11939)**

<details open>
<summary>ç›®å½•</summary>

- [rapidocr_openvino](#rapidocr_openvino)
    - [å®‰è£…](#å®‰è£…)
    - [æ¨¡å‹é—®é¢˜](#æ¨¡å‹é—®é¢˜)
    - [å…³äºOpenVINO](#å…³äºopenvino)
    - [OpenVINOä¸ONNXRuntimeæ€§èƒ½å¯¹æ¯”](#openvinoä¸onnxruntimeæ€§èƒ½å¯¹æ¯”)
    - [OpenVINOä¸ONNXRuntimeæ¨ç†ä»£ç å†™æ³•å¯¹æ¯”](#openvinoä¸onnxruntimeæ¨ç†ä»£ç å†™æ³•å¯¹æ¯”)
</details>


#### å®‰è£…
```bash
# Windowsç«¯
pip install openvino==2022.2.0

# é‡Œé¢å«æœ‰mo
pip install openvino-dev==2022.2.0
```

#### æ¨¡å‹é—®é¢˜
- å› ä¸ºOpenVINOå¯ä»¥ç›´æ¥æ¨ç†ONNXæ¨¡å‹ï¼Œæ•…è¿™é‡Œæš‚æ—¶ä¸ä½œè½¬æ¢ï¼Œç›´æ¥æ¨ç†ä¹‹å‰ONNXæ¨¡å‹å³å¯
- è¿™é‡Œä»ç„¶ç»™å‡ºè½¬æ¢çš„ä»£ç ï¼Œç”¨ä½œå‚è€ƒ:
    ```bash
    mo --input_model models/ch_PP-OCRv2_det_infer.onnx --output_dir models/IR/

    mo --input_model models/ch_PP-OCRv2_det_infer.onnx \
    --output_dir models/IR/static \
    --input_shape "[1,3,12128,800]"
    ```


#### å…³äºOpenVINO
- OpenVINOå¯ä»¥ç›´æ¥æ¨ç†IRã€ONNXå’ŒPaddlePaddleæ¨¡å‹ï¼Œå…·ä½“å¦‚ä¸‹(å›¾æ¥æº:[link](https://docs.openvino.ai/latest/openvino_docs_OV_UG_OV_Runtime_User_Guide.html#doxid-openvino-docs-o-v-u-g-o-v-runtime-user-guide))ï¼š

    <div align="center">
        <img src="https://docs.openvino.ai/latest/_images/BASIC_FLOW_IE_C.svg">
    </div>

- å’ŒONNXRuntimeåŒæ—¶æ¨ç†åŒä¸€ä¸ªONNXæ¨¡å‹ï¼ŒOpenVINOæ¨ç†é€Ÿåº¦æ›´å¿«
- ä½†æ˜¯ä»å¯¹æ¯”æ¥çœ‹ï¼ŒOpenVINOå ç”¨å†…å­˜æ›´å¤§ï¼Œå…¶åŸå› æ˜¯æ‹¿ç©ºé—´æ¢çš„æ—¶é—´
  - å½“æŒ‡å®š`input_shape`åœ¨ä¸€ä¸ªåŒºé—´èŒƒå›´æ—¶ï¼Œæ¨ç†æ—¶å†…å­˜å ç”¨ä¼šå‡å°‘ä¸€äº›
  - ç¤ºä¾‹å‘½ä»¤:
    ```bash
    mo --input_model models/ch_PP-OCRv2_det_infer.onnx \
    --output_dir models/IR/static \
    --input_shape "[1,3,960:1200,800]"
    ```

#### OpenVINOä¸ONNXRuntimeæ€§èƒ½å¯¹æ¯”
- æ¨ç†è®¾å¤‡ï¼š`Windows 64ä½ Intel(R) Core(TM) i5-4210M CPU @ 2.60GHz   2.59 GHz`
- [æµ‹è¯•å›¾åƒå®½é«˜](https://drive.google.com/file/d/1iJcGvOVIdUlyOS52bBdvO8uzx8QORo5M/view?usp=sharing): `12119x810`

| æµ‹è¯•æ¨¡å‹                             | æ¨ç†æ¡†æ¶             | å ç”¨å†…å­˜(3æ¬¡å¹³å‡) | æ¨ç†æ—¶é—´(3æ¬¡å¹³å‡) |
| ------------------------------------ | -------------------- | ----------------- | ----------------- |
| `ch_PP-OCRv2_det_infer.onnx`         | `ONNXRuntime=1.10.0` | 0.8G              | 5.354s            |
| `ch_PP-OCRv2_det_infer.onnx`         | `openvino=2022.1.0`  | 3.225G            | 2.53s             |
| `ch_PP-OCRv2_det_infer.xml` FP32 åŠ¨æ€å›¾ | `openvino=2022.1.0`  | 3.175G            | 2.0455s           |


#### OpenVINOä¸ONNXRuntimeæ¨ç†ä»£ç å†™æ³•å¯¹æ¯”
NOTE: ä»¥`ch_ppocr_mobile_v2_det`ä¸­æ¨ç†ä»£ç ä¸ºä¾‹å­

- ONNXRuntime
    ```python
    import onnxruntime

    # å£°æ˜
    sess_opt = onnxruntime.SessionOptions()
    sess_opt.log_severity_level = 4
    sess_opt.enable_cpu_mem_arena = False
    session = onnxruntime.InferenceSession(det_model_path, sess_opt)
    input_name = session.get_inputs()[0].name
    output_name = session.get_outputs()[0].name

    # æ¨ç†
    preds = session.run([output_name], {input_name: img})
    ```

- OpenVINO
    ```python
    from openvino.runtime import Core

    # åˆå§‹åŒ–
    ie = Core()
    model_onnx = ie.read_model(det_model_path)
    compile_model = ie.compile_model(model=model_onnx, device_name='CPU')
    vino_session = compile_model.create_infer_request()

    # æ¨ç†
    vino_session.infer(inputs=[img])
    vino_preds = vino_session.get_output_tensor().data
    ```
